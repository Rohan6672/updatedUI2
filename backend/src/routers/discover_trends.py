from fastapi import APIRouter, HTTPException, status
from src.models.session_models import TrendSendRequest, SephoraTrendsReport, TrendItem, TrendCategory
from src.config.load_config import load_config
from src.utils.service import run_conversation
from src.utils.setup_log import setup_logger
from src.utils.file_output import save_final_response, create_session_summary
from pydantic import ValidationError
from datetime import datetime
import json

logger = setup_logger()

router = APIRouter(prefix="/analysis", tags=["chat"])

@router.post("/")
async def chat(request: TrendSendRequest):
    """
    Process a query and return multiple beauty trends.
    """
    logger.info("=== TREND DISCOVERY REQUEST RECEIVED ===")
    logger.info(f"Session ID: {request.session_id}")
    logger.info(f"User ID: {request.user_id}")
    logger.info(f"Trend Query: '{request.trend_query}'")
    logger.info(f"Request timestamp: {request.created_at}")
    
    try:
        logger.info("=== STARTING AGENT CONVERSATION ===")
        trends_report = await run_conversation(request)
        logger.info(f"=== AGENT CONVERSATION COMPLETED ===")
        logger.info(f"Received trends report type: {type(trends_report)}")
        logger.info(f"Received trends report keys: {trends_report.keys() if isinstance(trends_report, dict) else 'Not a dict'}")
        
        # Check if we got None or empty result
        if not trends_report:
            logger.error("ERROR: No trends report generated by agent")
            raise ValueError("No trends report generated")
        
        # If it's a dictionary, extract data directly and format for frontend
        if isinstance(trends_report, dict):
            logger.info("=== PROCESSING TRENDS DATA ===")
            
            # Extract trends data
            trends_data = trends_report.get('trends', {})
            logger.info(f"Trends data structure: {trends_data.keys() if trends_data else 'Empty trends data'}")
            
            makeup_trends = trends_data.get('makeup_trends', [])
            skincare_trends = trends_data.get('skincare_trends', [])
            hair_trends = trends_data.get('hair_trends', [])
            tools_brushes_trends = trends_data.get('tools_brushes_trends', [])
            mini_size_trends = trends_data.get('mini_size_trends', [])
            men_trends = trends_data.get('men_trends', [])
            gifts_trends = trends_data.get('gifts_trends', [])
            fragrance_trends = trends_data.get('fragrance_trends', [])
            bath_body_trends = trends_data.get('bath_body_trends', [])
            
            # Calculate total trends
            total_trends = (len(makeup_trends) + len(skincare_trends) + len(hair_trends) + 
                          len(tools_brushes_trends) + len(mini_size_trends) + len(men_trends) +
                          len(gifts_trends) + len(fragrance_trends) + len(bath_body_trends))
            
            logger.info(f"=== EXTRACTED TRENDS SUMMARY ===")
            logger.info(f"Makeup trends: {len(makeup_trends)} items")
            logger.info(f"Skincare trends: {len(skincare_trends)} items")
            logger.info(f"Hair trends: {len(hair_trends)} items")
            logger.info(f"Tools & Brushes trends: {len(tools_brushes_trends)} items")
            logger.info(f"Mini Size trends: {len(mini_size_trends)} items")
            logger.info(f"Men trends: {len(men_trends)} items")
            logger.info(f"Gifts trends: {len(gifts_trends)} items")
            logger.info(f"Fragrance trends: {len(fragrance_trends)} items")
            logger.info(f"Bath & Body trends: {len(bath_body_trends)} items")
            logger.info(f"Total trends: {total_trends}")
            
            # Log sample trend data for debugging
            if makeup_trends:
                logger.info(f"Sample makeup trend: {makeup_trends[0].get('trend_name', 'No name')} - {makeup_trends[0].get('id', 'No ID')}")
            if skincare_trends:
                logger.info(f"Sample skincare trend: {skincare_trends[0].get('trend_name', 'No name')} - {skincare_trends[0].get('id', 'No ID')}")
            if hair_trends:
                logger.info(f"Sample hair trend: {hair_trends[0].get('trend_name', 'No name')} - {hair_trends[0].get('id', 'No ID')}")
            
            # Create response dictionary directly without Pydantic validation
            logger.info("=== BUILDING RESPONSE DATA ===")
            response_data = {
                "reportSummary": trends_report.get("report_summary", "No summary available"),
                "trends": {
                    "makeupTrends": makeup_trends,
                    "skincareTrends": skincare_trends,
                    "hairTrends": hair_trends,
                    "toolsBrushesTrends": tools_brushes_trends,
                    "miniSizeTrends": mini_size_trends,
                    "menTrends": men_trends,
                    "giftsTrends": gifts_trends,
                    "fragranceTrends": fragrance_trends,
                    "bathBodyTrends": bath_body_trends
                },
                "discoveryDate": trends_report.get("discovery_date", datetime.utcnow().strftime("%Y-%m-%d")),
                "totalTrendsFound": total_trends
            }
            
            logger.info(f"=== RESPONSE READY ===")
            logger.info(f"Response contains {total_trends} total trends")
            logger.info(f"Report summary length: {len(response_data.get('reportSummary', ''))}")
            logger.info(f"Discovery date: {response_data.get('discoveryDate')}")
            
            # Save final response to file and export to CSV/Excel
            config_data = load_config()
            output_dir = config_data.get("output_folder", {}).get("OUTPUT_DIR", "src/data/outputs")
            response_file = save_final_response(
                response_data, 
                request.session_id, 
                request.user_id,
                request.trend_query,  # Pass the query for metadata
                output_dir
            )
            logger.info(f"Final response saved to: {response_file}")
            
            # Create session summary with all files
            summary_file = create_session_summary(
                request.session_id,
                request.user_id,
                request.trend_query,
                output_dir
            )
            logger.info(f"Session summary created: {summary_file}")
            
            logger.info("=== RETURNING TRENDS DATA TO CLIENT ===")
            
            return response_data
            
        logger.info("=== RETURNING RAW TRENDS REPORT ===")
        return trends_report
        
    except ValidationError as ve:
        logger.error(f"Pydantic validation error: {ve}")
        config_data = load_config()
        error_msg = f"Data validation error: {str(ve)}"
        raise HTTPException(
            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
            detail=error_msg
        )
    except Exception as e:
        config_data = load_config()
        error_msg = config_data.get('error_messages', {}).get('technical_issue', f"Error: {str(e)}")
        logger.error(f"Error in chat endpoint: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=error_msg
        )